"""
Justi-Q Streamlit í”„ë¡ íŠ¸ì—”ë“œ
í˜•ì‚¬ë²• RAG ì‹œìŠ¤í…œ ì›¹ ì¸í„°í˜ì´ìŠ¤
"""

import sys
sys.path.append("src")

import streamlit as st
from vectorstore import VectorStore
from rag_chain import RAGChain


# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Justi-Q í˜•ì‚¬ë²• AI",
    page_icon="âš–ï¸",
    layout="wide"
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
@st.cache_resource
def load_rag_system():
    """RAG ì‹œìŠ¤í…œ ë¡œë“œ (ìºì‹±)"""
    vectorstore = VectorStore(
        collection_name="legal_documents",
        persist_dir="chroma_db"
    )
    rag_chain = RAGChain(vectorstore)
    return rag_chain


def main():
    # í—¤ë”
    st.title("âš–ï¸ Justi-Q í˜•ì‚¬ë²• AI")
    st.markdown("í˜•ì‚¬ë²• ê´€ë ¨ ì§ˆë¬¸ì— íŒë¡€ì™€ ë²•ë ¹ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•´ë“œë¦½ë‹ˆë‹¤.")
    st.divider()

    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("ì„¤ì •")
        n_results = st.slider("ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜", min_value=3, max_value=10, value=5)

        st.divider()
        st.header("ì •ë³´")
        st.markdown("""
        **ë°ì´í„° ì¶œì²˜:**
        - íŒë¡€ 750ê±´
        - ê²°ì •ë¬¸ 294ê±´
        - ë²•ë ¹ 898ê±´
        - í•´ì„ 58ê±´

        **ëª¨ë¸:**
        - ì„ë² ë”©: multilingual-e5-large
        - LLM: Llama 3.3 70B
        """)

    # RAG ì‹œìŠ¤í…œ ë¡œë“œ
    try:
        rag = load_rag_system()
    except Exception as e:
        st.error(f"ì‹œìŠ¤í…œ ë¡œë“œ ì‹¤íŒ¨: {e}")
        st.info("ë¨¼ì € `python main.py --index` ë¡œ ì¸ë±ì‹±ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        return

    # ì±„íŒ… íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ì´ì „ ë©”ì‹œì§€ í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            if "sources" in message:
                with st.expander("ğŸ“š ì°¸ê³  ë¬¸ì„œ"):
                    for src in message["sources"]:
                        st.markdown(f"- **[{src['type']}]** {src['doc_id']}")

    # ì‚¬ìš©ì ì…ë ¥
    if prompt := st.chat_input("í˜•ì‚¬ë²• ê´€ë ¨ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # AI ì‘ë‹µ ìƒì„±
        with st.chat_message("assistant"):
            with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                result = rag.query(prompt, n_results=n_results)

            st.markdown(result["answer"])

            # ì°¸ê³  ë¬¸ì„œ í‘œì‹œ
            with st.expander("ğŸ“š ì°¸ê³  ë¬¸ì„œ"):
                for src in result["sources"]:
                    st.markdown(f"- **[{src['type']}]** {src['doc_id']} (ìœ ì‚¬ë„: {1 - src['distance']:.2%})")

        # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ì €ì¥
        st.session_state.messages.append({
            "role": "assistant",
            "content": result["answer"],
            "sources": result["sources"]
        })


if __name__ == "__main__":
    main()
